{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "bbKb68XjMz47"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1 & 2: Load, Clean, and Prepare Data ---\n",
        "\n",
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('load_data.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'load_data.csv' not found. Please make sure the file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "# Clean column names by replacing special characters with '_'\n",
        "df.columns = df.columns.str.strip().str.replace('[^A-Za-z0-9]+', '_', regex=True).str.lower()\n",
        "\n",
        "# Convert 'date_time' column, ensuring day comes first\n",
        "df['date_time'] = pd.to_datetime(df['date_time'], dayfirst=True)"
      ],
      "metadata": {
        "id": "ygxFCG9uM1Ux"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "df['hour'] = df['date_time'].dt.hour\n",
        "df['dayofweek'] = df['date_time'].dt.dayofweek\n",
        "df['month'] = df['date_time'].dt.month\n",
        "\n",
        "# Sort dataframe by date\n",
        "df = df.sort_values(by='date_time').reset_index(drop=True)\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "df['load_type_encoded'] = le.fit_transform(df['load_type'])\n",
        "load_type_mapping = {index: label for index, label in enumerate(le.classes_)}\n",
        "\n",
        "print(\"--- Data Preparation Summary ---\")\n",
        "print(\"Load Type Mapping:\", load_type_mapping)\n",
        "print(\"Cleaned Column Names:\", df.columns.tolist())\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- Step 3: Data Splitting (Time-Based) ---\n",
        "last_month = df['date_time'].dt.month.iloc[-1]\n",
        "last_year = df['date_time'].dt.year.iloc[-1]\n",
        "split_date = df[(df['date_time'].dt.month == last_month) & (df['date_time'].dt.year == last_year)]['date_time'].min()\n",
        "\n",
        "train_df = df[df['date_time'] < split_date]\n",
        "test_df = df[df['date_time'] >= split_date]\n",
        "\n",
        "print(\"--- Data Splitting Summary ---\")\n",
        "print(f\"Training data runs from {train_df['date_time'].min()} to {train_df['date_time'].max()}\")\n",
        "print(f\"Test data runs from {test_df['date_time'].min()} to {test_df['date_time'].max()}\")\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whiZtxzFM1XB",
        "outputId": "4e3ca902-8540-41fe-fc6f-698c2ca46b7d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data Preparation Summary ---\n",
            "Load Type Mapping: {0: 'Light_Load', 1: 'Maximum_Load', 2: 'Medium_Load'}\n",
            "Cleaned Column Names: ['date_time', 'usage_kwh', 'lagging_current_reactive_power_kvarh', 'leading_current_reactive_power_kvarh', 'co2_tco2_', 'lagging_current_power_factor', 'leading_current_power_factor', 'nsm', 'load_type', 'hour', 'dayofweek', 'month', 'load_type_encoded']\n",
            "\n",
            "\n",
            "--- Data Splitting Summary ---\n",
            "Training data runs from 2018-01-01 00:00:00 to 2018-11-30 23:45:00\n",
            "Test data runs from 2018-12-01 00:00:00 to 2018-12-31 23:45:00\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS THE FINAL, ROBUST FIX:\n",
        "# Dynamically create the list of features instead of hardcoding it.\n",
        "non_feature_cols = ['date_time', 'load_type', 'load_type_encoded']\n",
        "features = [col for col in df.columns if col not in non_feature_cols]\n",
        "target = 'load_type_encoded'\n",
        "\n",
        "print(\"--- Features Used for Training ---\")\n",
        "print(features)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df[target]\n",
        "X_test = test_df[features]\n",
        "y_test = test_df[target]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTPYJqGjM1ZS",
        "outputId": "66d8a2b0-3b6c-4bdc-c883-16e5fec1634a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Features Used for Training ---\n",
            "['usage_kwh', 'lagging_current_reactive_power_kvarh', 'leading_current_reactive_power_kvarh', 'co2_tco2_', 'lagging_current_power_factor', 'leading_current_power_factor', 'nsm', 'hour', 'dayofweek', 'month']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FIX: Add this right before the model training loop ---\n",
        "# This ensures any and all missing values are filled.\n",
        "X_train = X_train.fillna(X_train.median())\n",
        "X_test = X_test.fillna(X_test.median())\n",
        "\n",
        "\n",
        "# --- Step 4 & 5: Model Training and Evaluation ---\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=2000, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# This loop will now work correctly\n",
        "for model_name, model in models.items():\n",
        "    print(f\"--- Training and Evaluating: {model_name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0)\n",
        "\n",
        "    results[model_name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"classification_report\": report\n",
        "    }\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzffzjWaM1dT",
        "outputId": "db5393dd-fffd-4866-9646-0ba37e616d55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training and Evaluating: Logistic Regression ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6480\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Light_Load       0.80      0.89      0.84      1745\n",
            "Maximum_Load       0.31      0.23      0.26       528\n",
            " Medium_Load       0.39      0.36      0.37       704\n",
            "\n",
            "    accuracy                           0.65      2977\n",
            "   macro avg       0.50      0.49      0.49      2977\n",
            "weighted avg       0.61      0.65      0.63      2977\n",
            "\n",
            "\n",
            "\n",
            "--- Training and Evaluating: Decision Tree ---\n",
            "Accuracy: 0.8905\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Light_Load       0.98      0.86      0.91      1745\n",
            "Maximum_Load       0.82      0.91      0.86       528\n",
            " Medium_Load       0.79      0.96      0.87       704\n",
            "\n",
            "    accuracy                           0.89      2977\n",
            "   macro avg       0.86      0.91      0.88      2977\n",
            "weighted avg       0.90      0.89      0.89      2977\n",
            "\n",
            "\n",
            "\n",
            "--- Training and Evaluating: Random Forest ---\n",
            "Accuracy: 0.9348\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Light_Load       0.99      0.92      0.95      1745\n",
            "Maximum_Load       0.89      0.94      0.91       528\n",
            " Medium_Load       0.86      0.98      0.92       704\n",
            "\n",
            "    accuracy                           0.93      2977\n",
            "   macro avg       0.91      0.94      0.93      2977\n",
            "weighted avg       0.94      0.93      0.94      2977\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Conclusion ---\n",
        "best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n",
        "print(f\"--- Final Conclusion ---\")\n",
        "print(f\"The best performing model is the '{best_model_name}' with an accuracy of {results[best_model_name]['accuracy']:.4f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9PkdrtHM1fo",
        "outputId": "bf06cf58-1678-460d-b83e-4b07670f2d0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Final Conclusion ---\n",
            "The best performing model is the 'Random Forest' with an accuracy of 0.9348.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0XEIdajoM1h7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}